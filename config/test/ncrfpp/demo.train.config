### use # to comment out the configure item

### I/O ###
train_dir=data/masakhaner/kin/train.txt
dev_dir=data/masakhaner/kin/dev.txt
test_dir=data/masakhaner/kin/test.txt
model_dir=experiments/TEST_baseline_vs_paranames/train/no_softgaz_largebatch/checkpoints/lstmcrf
#word_emb_dir=experiments/TEST_baseline_vs_paranames/checkpoints/word.emb

#raw_dir=
#decode_dir=
#dset_dir=
#load_model_dir=
#char_emb_dir=

norm_word_emb=False
norm_char_emb=False
number_normalized=True
seg=True
word_emb_dim=128
char_emb_dim=30

###NetworkConfiguration###
use_crf=True
use_char=True
word_seq_feature=LSTM
char_seq_feature=CNN
#feature=[POS] emb_size=20
#feature=[Cap] emb_size=20
#nbest=1

###TrainingSetting###
status=train
optimizer=SGD
iteration=50
batch_size=16
ave_batch_loss=False

###Hyperparameters###
#cnn_layer=4
char_hidden_dim=30
hidden_dim=200
dropout=0.5
lstm_layer=1
bilstm=True
learning_rate=0.015
lr_decay=0.05
momentum=0
l2=1e-8
clip=5
#gpu
